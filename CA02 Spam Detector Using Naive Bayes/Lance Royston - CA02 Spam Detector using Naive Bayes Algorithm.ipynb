{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b8c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CA02 Building a Spam Detector using Naive Bayes Algorithm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1370e458",
   "metadata": {},
   "source": [
    "# Function 1\n",
    "\n",
    "Initialization:\n",
    "The function initializes an empty list all_words which will eventually contain all the words found in the emails.\n",
    "\n",
    "\n",
    "Reading Emails:\n",
    "The function reads all the files in the directory specified by root_dir, which are individual emails.\n",
    "\n",
    "\n",
    "Word Collection:\n",
    "For each file, it opens the file and reads each line. It splits the lines into individual words and extends the all_words list with these words.\n",
    "\n",
    "\n",
    "Creating a Word Frequency Counter:\n",
    "The function then creates a Counter object from the collections module for all words that are both alphabetic and longer than one character. This is an important preprocessing step because it filters out non-word items (like numbers or punctuation) and very short words (like 'a' or 'I') which are typically not useful in distinguishing spam from non-spam.\n",
    "\n",
    "\n",
    "Selecting Top Features:\n",
    "The function returns the 3000 most common words from this collection, along with their frequencies. This subset of words will serve as the feature set for the Naive Bayes classifier. The assumption is that these common words will be the most informative in distinguishing between spam and non-spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0c829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_Dictionary(root_dir):\n",
    "    all_words = []\n",
    "    # Gather all words from the files\n",
    "    emails = [os.path.join(root_dir, f) for f in os.listdir(root_dir)]\n",
    "    for mail in emails:\n",
    "        with open(mail) as m:\n",
    "            for line in m:\n",
    "                all_words.extend(line.split())\n",
    "\n",
    "    # Create a Counter object for all words that are alphabetic and longer than one character\n",
    "    dictionary_counter = Counter(word for word in all_words if word.isalpha() and len(word) > 1)\n",
    "\n",
    "    # Return the 3000 most common words as a list of tuples (word, frequency)\n",
    "    return dictionary_counter.most_common(3000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844fc39",
   "metadata": {},
   "source": [
    "# Function 2\n",
    "\n",
    "Conversion of Dictionary:\n",
    "The input dictionary is a list of tuples, where each tuple contains a word and its frequency. The function creates a word_index dictionary that maps each word to a unique index. This will be used to build a feature vector for each email, where the index corresponds to a word's position in the feature vector.\n",
    "\n",
    "\n",
    "Initialization of Feature Matrix and Labels:\n",
    "The features_matrix is initialized as a 2D NumPy array with zeros. Its dimensions are determined by the number of files (emails) and the length of the dictionary (number of features).\n",
    "\n",
    "train_labels is a 1D NumPy array initialized to store the labels (0 or 1) indicating whether each email is non-spam or spam, respectively.\n",
    "\n",
    "\n",
    "Processing Each Email:\n",
    "The function iterates over each file in the mail_dir directory.\n",
    "For each file, it reads the contents and splits the text of the email (assumed to be on the third line lines[2]) into individual words.\n",
    "\n",
    "\n",
    "Feature Extraction:\n",
    "For each word in the email, it looks up the word's index in the word_index dictionary.\n",
    "If the word is in the dictionary, it increments the corresponding element in the features_matrix for that email (docID) by 1. This process effectively counts the occurrences of each dictionary word in the email.\n",
    "\n",
    "\n",
    "Label Assignment:\n",
    "The function checks if the filename contains the substring 'spmsg'. If it does, the corresponding entry in train_labels is set to 1, indicating spam. Otherwise, it's set to 0, indicating non-spam.\n",
    "\n",
    "\n",
    "Output:\n",
    "The function returns the features_matrix and train_labels. The feature matrix is used as input to the Naive Bayes classifier, and the labels are used to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f72877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(mail_dir, dictionary):\n",
    "    # Assuming the dictionary passed in is a list of tuples (word, frequency)\n",
    "    # Convert it into a dictionary of word:index\n",
    "    word_index = {word[0]: idx for idx, word in enumerate(dictionary)}\n",
    "\n",
    "    files = [os.path.join(mail_dir, fi) for fi in os.listdir(mail_dir)]\n",
    "    features_matrix = np.zeros((len(files), len(dictionary)), dtype=np.int_)\n",
    "    train_labels = np.zeros(len(files), dtype=np.int_)\n",
    "\n",
    "    for docID, file in enumerate(files):\n",
    "        with open(file, 'r') as fi:\n",
    "            lines = fi.readlines()\n",
    "            if len(lines) > 2:\n",
    "                words = lines[2].split()\n",
    "                for word in words:\n",
    "                    wordID = word_index.get(word, -1)\n",
    "                    if wordID >= 0:\n",
    "                        features_matrix[docID, wordID] += 1\n",
    "        train_labels[docID] = 1 if 'spmsg' in file else 0\n",
    "\n",
    "    return features_matrix, train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c792842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathnames for testing and training data\n",
    "\n",
    "TRAIN_DIR = (\"/Users/lanceroyston/Downloads/MSBA 2023 - 2024/Spring 2024/Intro to Machine Learning BSAN 6070/CA's/CA02 Spam Detector Using Naive Bayes /train-mails\")\n",
    "TEST_DIR = (\"/Users/lanceroyston/Downloads/MSBA 2023 - 2024/Spring 2024/Intro to Machine Learning BSAN 6070/CA's/CA02 Spam Detector Using Naive Bayes /test-mails\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b80f66",
   "metadata": {},
   "source": [
    "# LABEL EXTRACTION\n",
    "\n",
    "The function make_Dictionary is called with TRAIN_DIR as an argument to create a dictionary of the most common words found in the training dataset.\n",
    "\n",
    "\n",
    "Feature Extraction for Training Data:\n",
    "extract_features is called with TRAIN_DIR and the previously created dictionary_list to extract the feature matrix and labels from the training data. The feature matrix contains the presence or counts of the dictionary words in each email, and the labels indicate whether each email is spam or not.\n",
    "\n",
    "\n",
    "Feature Extraction for Test Data:\n",
    "Similarly, extract_features is called with TEST_DIR and the dictionary_list to prepare the feature matrix and labels for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4ecd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from the training data\n",
    "dictionary_list = make_Dictionary(TRAIN_DIR)\n",
    "\n",
    "\n",
    "# Extract features and labels from the training data\n",
    "features_matrix, labels = extract_features(TRAIN_DIR, dictionary_list)\n",
    "\n",
    "# Extract features and labels from the test data\n",
    "test_features_matrix, test_labels = extract_features(TEST_DIR, dictionary_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321f3de",
   "metadata": {},
   "source": [
    "# RESULTS\n",
    "\n",
    "Model Training:\n",
    "A Gaussian Naive Bayes model is instantiated with GaussianNB().\n",
    "The model is then trained using the .fit() method with the training feature matrix and labels. The Gaussian Naive Bayes is a variant of the Naive Bayes algorithm that assumes the features follow a normal distribution, which is a reasonable assumption when dealing with word counts or frequencies.\n",
    "\n",
    "\n",
    "Model Prediction:\n",
    "After training, the model predicts the labels for the test data using the .predict() method and the test feature matrix. This step classifies each email in the test set as either spam or not spam.\n",
    "\n",
    "\n",
    "Accuracy Calculation:\n",
    "The accuracy of the model is calculated by comparing the predicted labels with the actual labels from the test set using the accuracy_score function. This score represents the proportion of test emails that were correctly classified by the model.\n",
    "\n",
    "\n",
    "Printing Results:\n",
    "The code prints statements to the console to inform the user of the different stages of execution, such as reading data, training the model, predicting labels, and the final accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74a081e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n",
      "Training Model using Gaussian Naive Bayes algorithm .....\n",
      "Training completed\n",
      "testing trained model to predict Test Data labels\n",
      "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
      "0.9653846153846154\n"
     ]
    }
   ],
   "source": [
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "\n",
    "\n",
    "# Training the Naive Bayes model\n",
    "print(\"Training Model using Gaussian Naive Bayes algorithm .....\")\n",
    "model = GaussianNB()\n",
    "model.fit(features_matrix, labels)\n",
    "print(\"Training completed\")\n",
    "    \n",
    "# Predicting the labels of the test data\n",
    "print(\"testing trained model to predict Test Data labels\")\n",
    "predicted_labels = model.predict(test_features_matrix)\n",
    "print(\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\") \n",
    "    \n",
    "# Calculating and printing the accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
